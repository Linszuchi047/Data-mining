{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, learning_curve, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "df_data= pd.concat([train_data, test_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title\n",
       "0    29.0\n",
       "1    47.0\n",
       "2     4.0\n",
       "3    22.0\n",
       "4    36.0\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracted title using name\n",
    "df_data['Title'] = df_data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "df_data['Title'] = df_data['Title'].replace(['Capt', 'Col', 'Countess', 'Don',\n",
    "                                               'Dr', 'Dona', 'Jonkheer', \n",
    "                                                'Major','Rev','Sir'],'Rare') \n",
    "df_data['Title'] = df_data['Title'].replace(['Mlle', 'Ms','Mme'],'Miss')\n",
    "df_data['Title'] = df_data['Title'].replace(['Lady'],'Mrs')\n",
    "df_data['Title'] = df_data['Title'].map({\"Mr\":0, \"Rare\" : 1, \"Master\" : 2,\"Miss\" : 3, \"Mrs\" : 4 })\n",
    "Ti = df_data.groupby('Title')['Age'].median()\n",
    "Ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ti_pred = df_data.groupby('Title')['Age'].median().values\n",
    "df_data['Ti_Age'] = df_data['Age']\n",
    "# Filling the missing age\n",
    "for i in range(0,5):\n",
    " # 0 1 2 3 4 5\n",
    "    df_data.loc[(df_data.Age.isnull()) & (df_data.Title == i),'Ti_Age'] = Ti_pred[i]\n",
    "df_data['Ti_Age'] = df_data['Ti_Age'].astype('int')\n",
    "df_data['Ti_Minor'] = ((df_data['Ti_Age']) < 16.0) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing values\n",
    "df_data['Fare'] = df_data['Fare'].fillna(df_data['Fare'].median())\n",
    "\n",
    "# Making Bins\n",
    "df_data['FareBin_4'] = pd.qcut(df_data['Fare'], 4)\n",
    "df_data['FareBin_5'] = pd.qcut(df_data['Fare'], 5)\n",
    "df_data['FareBin_6'] = pd.qcut(df_data['Fare'], 6)\n",
    "\n",
    "label = LabelEncoder()\n",
    "df_data['FareBin_Code_4'] = label.fit_transform(df_data['FareBin_4'])\n",
    "df_data['FareBin_Code_5'] = label.fit_transform(df_data['FareBin_5'])\n",
    "df_data['FareBin_Code_6'] = label.fit_transform(df_data['FareBin_6'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['FamilySize'] = df_data['SibSp'] + df_data['Parch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>Cumings, Mr. John Bradley</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Futrelle, Mr. Jacques Heath</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>Hilliard, Mr. Herbert Henry</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Palsson, Miss. Torborg Danira</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Palsson, Miss. Stina Viola</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>Palsson, Mrs. Nils (Alma Cornelia Berglund)</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>Palsson, Master. Paul Folke</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Johnson, Miss. Eleanor Ileen</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>Johnson, Master. Harold Theodor</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Name    Ticket     Fare  \\\n",
       "1     Cumings, Mrs. John Bradley (Florence Briggs Th...  PC 17599  71.2833   \n",
       "1125                          Cumings, Mr. John Bradley  PC 17599  71.2833   \n",
       "3          Futrelle, Mrs. Jacques Heath (Lily May Peel)    113803  53.1000   \n",
       "137                         Futrelle, Mr. Jacques Heath    113803  53.1000   \n",
       "6                               McCarthy, Mr. Timothy J     17463  51.8625   \n",
       "1037                        Hilliard, Mr. Herbert Henry     17463  51.8625   \n",
       "7                        Palsson, Master. Gosta Leonard    349909  21.0750   \n",
       "24                        Palsson, Miss. Torborg Danira    349909  21.0750   \n",
       "374                          Palsson, Miss. Stina Viola    349909  21.0750   \n",
       "567         Palsson, Mrs. Nils (Alma Cornelia Berglund)    349909  21.0750   \n",
       "1280                        Palsson, Master. Paul Folke    349909  21.0750   \n",
       "8     Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)    347742  11.1333   \n",
       "172                        Johnson, Miss. Eleanor Ileen    347742  11.1333   \n",
       "869                     Johnson, Master. Harold Theodor    347742  11.1333   \n",
       "\n",
       "     Cabin  FamilySize  Survived  \n",
       "1      C85           2       1.0  \n",
       "1125   C85           2       NaN  \n",
       "3     C123           2       1.0  \n",
       "137   C123           2       0.0  \n",
       "6      E46           1       0.0  \n",
       "1037   E46           1       NaN  \n",
       "7      NaN           5       0.0  \n",
       "24     NaN           5       0.0  \n",
       "374    NaN           5       0.0  \n",
       "567    NaN           5       0.0  \n",
       "1280   NaN           5       NaN  \n",
       "8      NaN           3       1.0  \n",
       "172    NaN           3       1.0  \n",
       "869    NaN           3       1.0  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deplicate_ticket = []\n",
    "for tk in df_data.Ticket.unique():\n",
    "    tem = df_data.loc[df_data.Ticket == tk, 'Fare']\n",
    "    #print(tem.count())\n",
    "    if tem.count() > 1:\n",
    "        #print(df_data.loc[df_data.Ticket == tk,['Name','Ticket','Fare']])\n",
    "        deplicate_ticket.append(df_data.loc[df_data.Ticket == tk,['Name','Ticket','Fare','Cabin','FamilySize','Survived']])\n",
    "deplicate_ticket = pd.concat(deplicate_ticket)\n",
    "deplicate_ticket.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people keep the same ticket: 596 \n",
      "people have connected information : 496\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Connected_Survival</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Survived\n",
       "Connected_Survival          \n",
       "0.0                    0.225\n",
       "0.5                    0.298\n",
       "1.0                    0.728"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# the same ticket family or friends\n",
    "df_data['Connected_Survival'] = 0.5 # default \n",
    "for _, df_grp in df_data.groupby('Ticket'):\n",
    "    if (len(df_grp) > 1):\n",
    "        for ind, row in df_grp.iterrows():\n",
    "            smax = df_grp.drop(ind)['Survived'].max()\n",
    "            smin = df_grp.drop(ind)['Survived'].min()\n",
    "            passID = row['PassengerId']\n",
    "            if (smax == 1.0):\n",
    "                df_data.loc[df_data['PassengerId'] == passID, 'Connected_Survival'] = 1\n",
    "            elif (smin==0.0):\n",
    "                df_data.loc[df_data['PassengerId'] == passID, 'Connected_Survival'] = 0\n",
    "#print\n",
    "print('people keep the same ticket: %.0f '%len(deplicate_ticket))\n",
    "print(\"people have connected information : %.0f\" \n",
    "      %(df_data[df_data['Connected_Survival']!=0.5].shape[0]))\n",
    "df_data.groupby('Connected_Survival')[['Survived']].mean().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df_data[:len(train_data)]\n",
    "test_data = df_data[len(train_data):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns\n",
    "train_data = train_data.drop(['Cabin','Name','PassengerId','Ticket','Age'], axis=1)\n",
    "# Remove the rows with missing values\n",
    "train_data = train_data.dropna(subset =  ['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop(['Cabin','Name','Ticket','Age','Survived'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "\n",
    "# Encode the sex column\n",
    "train_data.iloc[:, 2] = labelencoder.fit_transform(train_data.iloc[:, 2].values)\n",
    "test_data.iloc[:, 2] = labelencoder.fit_transform(test_data.iloc[:, 2].values)\n",
    "\n",
    "# Encode the embarked column\n",
    "train_data.iloc[:, 6] = labelencoder.fit_transform(train_data.iloc[:, 6].values)\n",
    "test_data.iloc[:, 6] = labelencoder.fit_transform(test_data.iloc[:, 6].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived              0\n",
       "Pclass                0\n",
       "Sex                   0\n",
       "SibSp                 0\n",
       "Parch                 0\n",
       "Fare                  0\n",
       "Embarked              0\n",
       "Title                 0\n",
       "Ti_Age                0\n",
       "Ti_Minor              0\n",
       "FareBin_4             0\n",
       "FareBin_5             0\n",
       "FareBin_6             0\n",
       "FareBin_Code_4        0\n",
       "FareBin_Code_5        0\n",
       "FareBin_Code_6        0\n",
       "FamilySize            0\n",
       "Connected_Survival    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId           0\n",
       "Pclass                0\n",
       "Sex                   0\n",
       "SibSp                 0\n",
       "Parch                 0\n",
       "Fare                  0\n",
       "Embarked              0\n",
       "Title                 0\n",
       "Ti_Age                0\n",
       "Ti_Minor              0\n",
       "FareBin_4             0\n",
       "FareBin_5             0\n",
       "FareBin_6             0\n",
       "FareBin_Code_4        0\n",
       "FareBin_Code_5        0\n",
       "FareBin_Code_6        0\n",
       "FamilySize            0\n",
       "Connected_Survival    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ['Sex', 'Pclass', 'FareBin_Code_5', 'Ti_Minor', 'FamilySize']\n",
    "y = train_data.iloc[:, 0].values  # Ensure this is the correct target variable\n",
    "\n",
    "# Split the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b4 oob score :0.84364\n",
      "b5 oob score :0.84477 \n",
      "b6 oob score : 0.84364\n"
     ]
    }
   ],
   "source": [
    "b4, b5, b6 = ['Sex', 'Pclass','FareBin_Code_4','Ti_Minor','Connected_Survival'], ['Sex','Pclass','FareBin_Code_5','Ti_Minor','Connected_Survival'],\\\n",
    "['Sex','Pclass','FareBin_Code_6','Ti_Minor','Connected_Survival']\n",
    "b4_Model = RandomForestClassifier(random_state=2,n_estimators=250,min_samples_split=20,oob_score=True)\n",
    "b4_Model.fit(train_data[b4], y)\n",
    "b5_Model = RandomForestClassifier(random_state=2,n_estimators=250,min_samples_split=20,oob_score=True)\n",
    "b5_Model.fit(train_data[b5], y)\n",
    "b6_Model = RandomForestClassifier(random_state=2,n_estimators=250,min_samples_split=20,oob_score=True)\n",
    "b6_Model.fit(train_data[b6], y)\n",
    "print('b4 oob score :%.5f' %(b4_Model.oob_score_))\n",
    "print('b5 oob score :%.5f '%(b5_Model.oob_score_))\n",
    "print('b6 oob score : %.5f' %(b6_Model.oob_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submits\n",
    "X_Submit = test_data.drop(labels=['PassengerId'],axis=1)\n",
    "\n",
    "b5_pred = b5_Model.predict(X_Submit[b5])\n",
    "\n",
    "submit = pd.DataFrame({\"PassengerId\": test_data['PassengerId'],\n",
    "                      \"Survived\":b5_pred.astype(int)})\n",
    "submit.to_csv(\"gender_submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_data[b5], y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Accuracy   ROC AUC\n",
      "Logistic Regression     0.741573  0.816960\n",
      "Random Forest           0.764045  0.819700\n",
      "Support Vector Machine  0.758427  0.800391\n",
      "K-Nearest Neighbors     0.775281  0.816960\n",
      "Decision Tree           0.758427  0.818852\n",
      "Gradient Boosting       0.769663  0.831050\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=2, n_estimators=250, min_samples_split=20, oob_score=True),\n",
    "    'Support Vector Machine': SVC(probability=True, random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(criterion='entropy', random_state=0),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "\n",
    "# Store results\n",
    "results = {}\n",
    "\n",
    "# Evaluate classifiers\n",
    "for name, clf in classifiers.items():\n",
    "    # Fit the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = clf.predict(X_val)\n",
    "    y_pred_proba = clf.predict_proba(X_val)[:, 1]  # Probabilities for ROC AUC\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\"Accuracy\": accuracy, \"ROC AUC\": roc_auc}\n",
    "    \n",
    "\n",
    "# Optional: Display results in a DataFrame for better readability\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_model_pipeline.joblib']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipeline = Pipeline(steps=[\n",
    "        ('Gradient Boosting', GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "\n",
    "# Fit the model\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "dump(model_pipeline, 'best_model_pipeline.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load('best_model_pipeline.joblib')\n",
    "# submits\n",
    "X_Submit = test_data.drop(labels=['PassengerId'],axis=1)\n",
    "\n",
    "b4_pred = model.predict(X_Submit[b5])\n",
    "\n",
    "submit = pd.DataFrame({\"PassengerId\": test_data['PassengerId'],\n",
    "                      \"Survived\":b4_pred.astype(int)})\n",
    "submit.to_csv(\"gender_submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
